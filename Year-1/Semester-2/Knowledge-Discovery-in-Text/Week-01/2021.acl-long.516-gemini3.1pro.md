# Propaganda Detection in Memes: Project Reference Guide

## Overview

This repository serves as a foundation for building systems capable of detecting propaganda techniques in multimodal content, specifically memes. The underlying methodology treats this as a multi-label multimodal task, recognizing that propaganda can appear in the text, the image, or a combination of both.

## Propaganda Techniques

The theoretical framework categorizes propaganda into 22 distinct techniques.

### Text and Image Techniques

The first 20 techniques can be identified in both textual and visual modalities:

* **Loaded language:** Using words with strong emotional implications to influence an audience.
* **Name calling or labeling:** Labeling the target as something the audience fears, hates, or loves.
* **Doubt:** Questioning the credibility of someone or something.
* **Exaggeration / Minimisation:** Representing something in an excessive manner or making it seem less important.
* **Appeal to fear / prejudices:** Instilling anxiety or panic to build support for an idea.
* **Slogans:** A brief, striking phrase that acts as an emotional appeal.
* **Whataboutism:** Discrediting an opponent by charging them with hypocrisy without disproving their argument.
* **Flag-waving:** Playing on strong national or group feelings to promote an idea.
* **Misrepresentation of someone's position (Straw man):** Substituting an opponent's proposition with a similar one to refute it.
* **Causal oversimplification:** Assuming a single cause when there are multiple causes.
* **Appeal to authority:** Stating a claim is true because an authority said it, without other evidence.
* **Thought-terminating clich√©:** Words or phrases that discourage critical thought.
* **Black-and-white fallacy or dictatorship:** Presenting two alternative options as the only possibilities.
* **Reductio ad hitlerum:** Persuading an audience to disapprove an idea by suggesting it is popular with hated groups.
* **Repetition:** Repeating the same message so the audience will accept it.
* **Obfuscation, Intentional vagueness, Confusion:** Using deliberately unclear words.
* **Presenting irrelevant data (Red Herring):** Introducing irrelevant material to divert attention.
* **Bandwagon:** Persuading the audience to take action because "everyone else is".
* **Smears:** Damaging a reputation by propounding negative propaganda.
* **Glittering generalities (Virtue):** Words or symbols that produce a positive image when attached to an issue.


### Image-Specific Techniques

Two techniques are strictly reserved for labeling images:

* **Appeal to (strong) emotions:** Using images with strong emotional implications.
* **Transfer:** Projecting positive or negative qualities of one entity onto another to make the latter more acceptable or discredit it.



## Technologies and Methodologies

### Data Processing
* **Text Extraction (OCR):** The Google Vision API can be used to automatically extract textual content from memes.

### Machine Learning Models

The problem can be tackled using various state-of-the-art architectures:

* **Unimodal (Text-Only):**
* **BERT:** A pre-trained Transformer model that captures contextual representations well.
* **fastText:** Highly tolerant of noisy social media text as it relies on word and character n-grams.
* **Unimodal (Image-Only):**
* **ResNet-152:** Used for visual modality feature extraction.
* **Multimodal (Unimodally Pretrained Fusion):**
* **Early Fusion:** Using Multimodal Bitransformers (MMBT).
* **Middle Fusion:** Taking the output of the [CLS] token from BERT and the second-to-last layer of ResNet-152, feeding them into a multilayer network.
* **Late Fusion:** Combining the final predictions of the separate models.
* **Multimodal (Joint Models):**
* **ViLBERT:** Pretrained on Conceptual Captions.
* **VisualBERT:** Pretrained on the MS-COCO dataset.

### Training & Evaluation Framework

* **Software Framework:** Multimodal Framework (MMF).
* **Hyper-parameters:** AdamW optimizer, learning rate of 5e-5, and a batch size of 32.
* **Metrics:** Because this is a multi-class multi-label task with imbalanced labels, the primary evaluation metric used is the micro-average $F_{1}$ score, supplemented by the macro-average $F_{1}$ score.



## Project Ideas

Based on the findings and future work suggested in the paper, here are some actionable project ideas:

1. **Multilingual Propaganda Detector:** The original study highlights the future goal of extending the dataset to include memes in other languages. You could build a pipeline that translates OCR-extracted text and applies cross-lingual Transformer models (like mBERT or XLM-R) to detect propaganda in non-English domains.


2. **Explainable Multimodal Meme Analyzer:** The paper points out the need for deeper understanding of the relation between text and images. You could build an interactive web app where users upload a meme, and the system uses bounding boxes or attention heatmaps to visually explain *why* a specific technique (like *Smears* or *Transfer*) was flagged.


3. **Real-time Browser Extension:** Since identifying malicious memes quickly is crucial , you could package the BERT + ResNet-152 mid-fusion architecture  into a browser extension that alerts users to potential computational propaganda on their social media feeds.
